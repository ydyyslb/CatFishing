import json
import math
import os
import re
import shutil
import time
import warnings
from typing import Optional

import chardet
import networkx as nx
import numpy as np
import pandas as pd
import requests
from causallearn.graph.Edge import Edge
from causallearn.graph.Endpoint import Endpoint
from causallearn.graph.GeneralGraph import GeneralGraph
from causallearn.graph.GraphNode import GraphNode
from causallearn.score.LocalScoreFunctionClass import LocalScoreClass
from causallearn.utils.GESUtils import *
from causallearn.utils.TXT2GeneralGraph import mod_endpoint, to_endpoint
from retry import retry
from rich import print as rprint

# from simulator import simDAG

# ç”¨äºå°†ä¸€ä¸ª NumPy æ•°ç»„è½¬æ¢ä¸ºä¸€ä¸ª GeneralGraph å¯¹è±¡ã€‚
# A: ä¸€ä¸ªäºŒç»´ NumPy æ•°ç»„ï¼Œå…¶ä¸­åŒ…å«æœ‰å‘å›¾çš„é‚»æ¥çŸ©é˜µã€‚
def array2generalgraph(A: np.ndarray) -> GeneralGraph:
    # è·å–æ•°ç»„ A çš„è¡Œæ•°å’Œåˆ—æ•°ï¼Œåˆ†åˆ«å­˜å‚¨åœ¨å˜é‡ n å’Œ m ä¸­ã€‚
    n, m = A.shape
    g = GeneralGraph([])
    # åˆ›å»ºä¸€ä¸ªç©ºå­—å…¸ node_mapï¼Œç”¨äºå­˜å‚¨å›¾ä¸­çš„èŠ‚ç‚¹å’Œå®ƒä»¬çš„ç´¢å¼•ã€‚
    node_map = {}
    for i in range(n):
        node = 'X'+str(i+1)
        node_map[node] = GraphNode(node)
        g.add_node(node_map[node])
    B = A+A.T
    for i in range(n):
        for j in range(i+1, n):
            if B[i, j] == 1:
                node1 = 'X'+str(i+1)
                node2 = 'X'+str(j+1)
                edge = Edge(node_map[node1], node_map[node2],
                            Endpoint.CIRCLE, Endpoint.CIRCLE)
                if A[i, j] == 1:
                    mod_endpoint(edge, node_map[node2], Endpoint.ARROW)
                else:
                    mod_endpoint(edge, node_map[node2], Endpoint.TAIL)
                if A[j, i] == 1:
                    mod_endpoint(edge, node_map[node1], Endpoint.ARROW)
                else:
                    mod_endpoint(edge, node_map[node1], Endpoint.TAIL)
                g.add_edge(edge)
    return g

# ç”¨äºå°†ä¸€ä¸ªå­—å…¸è½¬æ¢ä¸ºä¸€ä¸ª GeneralGraph å¯¹è±¡ã€‚
# dict2generalgraph å‡½æ•°ç”¨äºå°†ä¸€ä¸ªåŒ…å«èŠ‚ç‚¹å’Œçˆ¶èŠ‚ç‚¹ä¿¡æ¯çš„å­—å…¸è½¬æ¢ä¸ºä¸€ä¸ªæœ‰å‘å›¾å¯¹è±¡ã€‚è¿™ä¸ªå‡½æ•°é€šè¿‡éå†å­—å…¸ä¸­çš„æ¯ä¸ªé”®ï¼Œ
# ä¸ºæ¯ä¸ªé”®å¯¹åº”çš„èŠ‚ç‚¹åˆ›å»ºä¸€ä¸ª GraphNode å¯¹è±¡ï¼Œå¹¶ä¸ºæ¯ä¸ªé”®å¯¹åº”çš„çˆ¶èŠ‚ç‚¹åˆ—è¡¨ä¸­çš„æ¯ä¸ªçˆ¶èŠ‚ç‚¹åˆ›å»ºä¸€ä¸ªä»çˆ¶èŠ‚ç‚¹åˆ°å½“å‰èŠ‚ç‚¹çš„æœ‰å‘è¾¹ã€‚
# A: ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­åŒ…å«æœ‰å‘å›¾çš„èŠ‚ç‚¹å’Œå®ƒä»¬çš„çˆ¶èŠ‚ç‚¹ä¿¡æ¯ã€‚
def dict2generalgraph(A: dict) -> GeneralGraph:
    #  åˆ›å»ºä¸€ä¸ªæ–°çš„ GeneralGraph å¯¹è±¡ gï¼Œå¹¶å°†å…¶åˆå§‹åŒ–ä¸ºç©ºå›¾ã€‚
    g = GeneralGraph([])
    # åˆ›å»ºä¸€ä¸ªç©ºå­—å…¸ node_mapï¼Œç”¨äºå­˜å‚¨å›¾ä¸­çš„èŠ‚ç‚¹å’Œå®ƒä»¬çš„ç´¢å¼•ã€‚
    node_map = {}
    for key in A:
        #  åœ¨ node_map å­—å…¸ä¸­æ·»åŠ ä¸€ä¸ªé”®å€¼å¯¹ï¼Œé”®æ˜¯èŠ‚ç‚¹çš„åç§°ï¼Œå€¼æ˜¯åˆ›å»ºçš„ GraphNode å¯¹è±¡ã€‚
        node_map[key] = GraphNode(key)
        # å°† GraphNode å¯¹è±¡æ·»åŠ åˆ°å›¾ g ä¸­ã€‚
        g.add_node(node_map[key])
    for key in A:
        for pa in A[key]['par']:
            edge = Edge(node_map[pa], node_map[key],
                        Endpoint.TAIL, Endpoint.ARROW)
            g.add_edge(edge)
    return g

# directed_edge2array å‡½æ•°ç”¨äºå°†ä¸€ä¸ªåŒ…å«æœ‰å‘è¾¹ä¿¡æ¯çš„åˆ—è¡¨è½¬æ¢ä¸ºä¸€ä¸ª NumPy æ•°ç»„ï¼Œå…¶ä¸­æ•°ç»„ä¸­çš„æ¯ä¸ªå…ƒç´ ä»£è¡¨å›¾ä¸­æ˜¯å¦å­˜åœ¨ä¸€æ¡ä»ç›¸åº”çš„è¡Œç´¢å¼•åˆ°åˆ—ç´¢å¼•çš„æœ‰å‘è¾¹ã€‚
def directed_edge2array(n: int, L: list) -> np.ndarray:
    A = np.zeros([n, n])
    for i in L:
        A[i[0], i[1]] = 1
    return A

# array2directed_edge å‡½æ•°ç”¨äºå°†ä¸€ä¸ª NumPy æ•°ç»„è½¬æ¢ä¸ºä¸€ä¸ªåŒ…å«æœ‰å‘è¾¹ä¿¡æ¯çš„åˆ—è¡¨ã€‚é€šè¿‡æ‰¾åˆ°æ•°ç»„ä¸­éé›¶å…ƒç´ çš„ç´¢å¼•ï¼Œç„¶åå°†è¿™äº›ç´¢å¼•é…å¯¹æˆå…ƒç»„ï¼Œæœ€åå°†è¿™äº›å…ƒç»„è½¬æ¢ä¸ºåˆ—è¡¨ã€‚
def array2directed_edge(A: np.ndarray) -> list:
    a, b = np.where(A != 0)
    return list(zip(a, b))

# array2no_edge å‡½æ•°ç”¨äºå°†ä¸€ä¸ª NumPy æ•°ç»„è½¬æ¢ä¸ºä¸€ä¸ªåŒ…å«æ— å‘è¾¹ä¿¡æ¯çš„åˆ—è¡¨ã€‚é€šè¿‡æ‰¾åˆ°æ•°ç»„ä¸­æ‰€æœ‰å…ƒç´ ä¸º 0 çš„ç´¢å¼•ï¼Œç„¶åå°†è¿™äº›ç´¢å¼•é…å¯¹æˆå…ƒç»„ï¼Œæœ€åå°†è¿™äº›å…ƒç»„è½¬æ¢ä¸ºåˆ—è¡¨ã€‚
def array2no_edge(A: np.ndarray) -> list:
    a, b = np.where(A == 0)
    return list(zip(a, b))

# ShowGraph å‡½æ•°ç”¨äºå°†ä¸€ä¸ª GeneralGraph å¯¹è±¡è½¬æ¢ä¸º Pydot æ ¼å¼ï¼Œç„¶åå°†å…¶æ¸²æŸ“ä¸º PNG å›¾åƒï¼Œå¹¶ä½¿ç”¨ matplotlib æ¨¡å—åœ¨å›¾å½¢ä¸­æ˜¾ç¤ºè¯¥å›¾åƒã€‚è¿™ä¸ªå‡½æ•°é€‚ç”¨äºå¯è§†åŒ–å›¾ç»“æ„ï¼Œä½¿å¾—å›¾çš„èŠ‚ç‚¹å’Œè¾¹ä»¥å›¾å½¢çš„å½¢å¼ç›´è§‚åœ°å±•ç¤ºå‡ºæ¥ã€‚
def ShowGraph(a: GeneralGraph):
    import io

    import matplotlib.image as mpimg
    import matplotlib.pyplot as plt
    from causallearn.utils.GraphUtils import GraphUtils
    pyd = GraphUtils.to_pydot(a)
    tmp_png = pyd.create_png(f="png")
    fp = io.BytesIO(tmp_png)
    img = mpimg.imread(fp, format='png')
    plt.axis('off')
    plt.imshow(img)
    plt.show()

# ç”¨äºè®¡ç®—ä¸€ä¸ªå›¾æ¨¡å‹ï¼ˆGeneralGraphï¼‰ä¸æ•°æ®é›†ï¼ˆndarrayï¼‰ä¹‹é—´çš„è¯„åˆ†ã€‚è¿™ä¸ªè¯„åˆ†å‡½æ•°ä¾èµ–äºä¸åŒçš„è¯„åˆ†å‡½æ•°å’Œå‚æ•°ã€‚
# score_func: ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºä½¿ç”¨çš„è¯„åˆ†å‡½æ•°ï¼Œé»˜è®¤ä¸º â€˜local_score_BICâ€™ã€‚
# G: ä¸€ä¸ª GeneralGraph å¯¹è±¡ï¼Œè¡¨ç¤ºå›¾æ¨¡å‹ï¼Œé»˜è®¤ä¸º Noneã€‚
# maxP: ä¸€ä¸ªå¯é€‰çš„æµ®ç‚¹æ•°ï¼Œè¡¨ç¤ºå›¾æ¨¡å‹ä¸­èŠ‚ç‚¹çš„æœ€å¤§çˆ¶èŠ‚ç‚¹æ•°é‡ï¼Œé»˜è®¤ä¸º Noneã€‚
# parameters: ä¸€ä¸ªå¯é€‰çš„å­—å…¸ï¼ŒåŒ…å«è¯„åˆ†å‡½æ•°çš„å‚æ•°ï¼Œé»˜è®¤ä¸º Noneã€‚
def truth_score(X: ndarray, score_func: str = 'local_score_BIC', G: GeneralGraph = None, maxP: Optional[float] = None, parameters: Optional[Dict[str, Any]] = None):

    #  å¦‚æœæ•°æ®é›†çš„è¡Œæ•°å°äºåˆ—æ•°ï¼Œå³ç‰¹å¾æ•°é‡å¤§äºæ ·æœ¬æ•°é‡ï¼Œ
    if X.shape[0] < X.shape[1]:
        warnings.warn(
            "The number of features is much larger than the sample size!")

    # å°†è¾“å…¥çš„ NumPy æ•°ç»„è½¬æ¢ä¸ºçŸ©é˜µç±»å‹ï¼Œä»¥ä¾¿åç»­ä½¿ç”¨ã€‚
    X = np.mat(X)
    # % k-fold negative cross validated likelihood based on regression in RKHS
    # è¯´æ˜æ¥ä¸‹æ¥çš„ä»£ç æ˜¯ä½¿ç”¨ k æŠ˜äº¤å‰éªŒè¯æ¥è®¡ç®—åŸºäº RKHS çš„è´Ÿå¯¹æ•°ä¼¼ç„¶è¯„åˆ†ã€‚
    # å¦‚æœè¯„åˆ†å‡½æ•°æ˜¯ â€˜local_score_CV_generalâ€™ï¼Œ
    if score_func == 'local_score_CV_general':
        if parameters is None:
            parameters = {'kfold': 10,  # 10 fold cross validation
                          'lambda': 0.01}  # regularization parameter
        if maxP is None:
            maxP = X.shape[1] / 2  # maximum number of parents
        N = X.shape[1]  # number of variables
        localScoreClass = LocalScoreClass(
            data=X, local_score_fun=local_score_cv_general, parameters=parameters)

    # negative marginal likelihood based on regression in RKHS
    # å¦‚æœè¯„åˆ†å‡½æ•°æ˜¯ â€˜local_score_marginal_generalâ€™
    elif score_func == 'local_score_marginal_general':
        parameters = {}
        if maxP is None:
            maxP = X.shape[1] / 2  # maximum number of parents
        N = X.shape[1]  # number of variables
        localScoreClass = LocalScoreClass(
            data=X, local_score_fun=local_score_marginal_general, parameters=parameters)

    # k-fold negative cross validated likelihood based on regression in RKHS
    # å¦‚æœè¯„åˆ†å‡½æ•°æ˜¯ â€˜local_score_CV_multiâ€™
    elif score_func == 'local_score_CV_multi':
        # for data with multi-variate dimensions
        if parameters is None:
            parameters = {'kfold': 10, 'lambda': 0.01,
                          'dlabel': {}}  # regularization parameter
            for i in range(X.shape[1]):
                parameters['dlabel']['{}'.format(i)] = i
        if maxP is None:
            maxP = len(parameters['dlabel']) / 2
        N = len(parameters['dlabel'])
        localScoreClass = LocalScoreClass(
            data=X, local_score_fun=local_score_cv_multi, parameters=parameters)

    # negative marginal likelihood based on regression in RKHS
    elif score_func == 'local_score_marginal_multi':
        # for data with multi-variate dimensions
        if parameters is None:
            parameters = {'dlabel': {}}
            for i in range(X.shape[1]):
                parameters['dlabel']['{}'.format(i)] = i
        if maxP is None:
            maxP = len(parameters['dlabel']) / 2
        N = len(parameters['dlabel'])
        localScoreClass = LocalScoreClass(
            data=X, local_score_fun=local_score_marginal_multi, parameters=parameters)

    # Greedy equivalence search with BIC score
    elif score_func == 'local_score_BIC' or score_func == 'local_score_BIC_from_cov':
        if maxP is None:
            maxP = X.shape[1] / 2
        N = X.shape[1]  # number of variables
        parameters = {}
        parameters["lambda_value"] = 2
        localScoreClass = LocalScoreClass(
            data=X, local_score_fun=local_score_BIC_from_cov, parameters=parameters)

    elif score_func == 'local_score_BDeu':  # Greedy equivalence search with BDeu score
        if maxP is None:
            maxP = X.shape[1] / 2
        N = X.shape[1]  # number of variables
        localScoreClass = LocalScoreClass(
            data=X, local_score_fun=local_score_BDeu, parameters=None)

    else:
        raise Exception('Unknown function!')
    score_func = localScoreClass

    score = score_g(X, G, score_func, parameters)  # initialize the score

    return score

# dict2list å‡½æ•°å°†ä¸€ä¸ªåŒ…å«å›¾è¾¹ä¿¡æ¯çš„å­—å…¸è½¬æ¢ä¸ºä¸€ä¸ªåŒ…å«ç‰¹å®šæ ¼å¼å­—ç¬¦ä¸²çš„åˆ—è¡¨ã€‚
# è¿™ä¸ªåˆ—è¡¨ä¸­çš„æ¯ä¸ªå­—ç¬¦ä¸²éƒ½åŒ…å«äº†è¾¹çš„ç´¢å¼•ã€è¾¹çš„æƒé‡ã€çœŸå®å›¾ä¸­è¾¹çš„ç±»å‹ï¼ˆæ— å‘ã€æœ‰å‘æˆ–ä¸å­˜åœ¨ï¼‰ã€é¢„æµ‹å›¾ä¸­è¾¹çš„ç±»å‹ï¼ˆæ— å‘ã€æœ‰å‘æˆ–ä¸å­˜åœ¨ï¼‰ä»¥åŠåˆ†éš”ç¬¦ â€˜;â€™ã€‚
# D: ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å«å›¾çš„è¾¹ä¿¡æ¯ã€‚
# G: ä¸€ä¸ª GeneralGraph å¯¹è±¡ï¼Œè¡¨ç¤ºçœŸå®å›¾ã€‚
# P: ä¸€ä¸ª GeneralGraph å¯¹è±¡ï¼Œè¡¨ç¤ºé¢„æµ‹å›¾ã€‚
def dict2list(D, G, P):
    result = []
    for edge in D:
        i, j = edge[1]
        # æ£€æŸ¥çœŸå®å›¾ä¸­ä½äº (i-1, j-1) çš„å…ƒç´ æ˜¯å¦ä¸º -1ï¼Œå³æ˜¯å¦å­˜åœ¨æ— å‘è¾¹ã€‚
        if G.graph[i-1, j-1] == -1:
            flag1 = 'y'
        #  å¦‚æœçœŸå®å›¾ä¸­ä½äº (i-1, j-1) çš„å…ƒç´ ä¸ä¸º -1
        else:
            # æ£€æŸ¥çœŸå®å›¾ä¸­ä½äº (i-1, j-1) çš„å…ƒç´ æ˜¯å¦ä¸º 1ï¼Œå³æ˜¯å¦å­˜åœ¨æœ‰å‘è¾¹ã€‚
            if G.graph[i-1, j-1] == 1:
                flag1 = 'r'
            else:
                flag1 = 'n'
        #   æ£€æŸ¥é¢„æµ‹å›¾ä¸­ä½äº (i-1, j-1) çš„å…ƒç´ æ˜¯å¦ä¸º -1ï¼Œå³æ˜¯å¦å­˜åœ¨æ— å‘è¾¹ã€‚
        if P.graph[i-1, j-1] == -1:
            flag2 = 'y'
        # å¦‚æœé¢„æµ‹å›¾ä¸­ä½äº (i-1, j-1) çš„å…ƒç´ ä¸ä¸º -1
        else:
            if P.graph[i-1, j-1] == 1:
                flag2 = 'r'
            else:
                flag2 = 'n'
        #  å°†è¾¹çš„ç´¢å¼•ã€è¾¹çš„æƒé‡ã€çœŸå®å›¾ä¸­è¾¹çš„ç±»å‹ã€é¢„æµ‹å›¾ä¸­è¾¹çš„ç±»å‹ä»¥åŠåˆ†éš”ç¬¦ â€˜;â€™ ç»„åˆæˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ° result åˆ—è¡¨ä¸­ã€‚
        result.append(str((i, j, edge[0], flag1, flag2))+';')
    return result

# ç”¨äºå°†ä¸€ä¸ª NumPy æ•°ç»„è½¬æ¢ä¸ºä¸€ä¸ªå­—å…¸ï¼Œè¿™ä¸ªå­—å…¸è¡¨ç¤ºä¸€ä¸ªæœ‰å‘å›¾çš„é‚»æ¥ä¿¡æ¯ã€‚
def array2dict(A: np.ndarray, varnames):
    dag = {}
    n, m = A.shape
    for i in range(n):
        # åœ¨å­—å…¸ dag ä¸­ä¸ºå½“å‰è¡Œçš„èŠ‚ç‚¹åç§°åˆ›å»ºä¸€ä¸ªé”®å€¼å¯¹ï¼Œå€¼ä¸ºä¸€ä¸ªç©ºå­—å…¸ã€‚
        dag[varnames[i]] = {}
        # åœ¨å½“å‰èŠ‚ç‚¹çš„å­—å…¸ä¸­åˆ›å»ºä¸€ä¸ªé”® â€˜parâ€™ï¼Œå…¶å€¼ä¸ºä¸€ä¸ªç©ºåˆ—è¡¨
        dag[varnames[i]]['par'] = []
        # åœ¨å½“å‰èŠ‚ç‚¹çš„å­—å…¸ä¸­åˆ›å»ºä¸€ä¸ªé”® â€˜neiâ€™ï¼Œå…¶å€¼ä¸ºä¸€ä¸ªç©ºåˆ—è¡¨ã€‚
        dag[varnames[i]]['nei'] = []
    for i in range(n):
        for j in range(m):
            # å¦‚æœ A ä¸­ä½äº (i, j) çš„å…ƒç´ ä¸º 1ï¼Œè¡¨ç¤º A ä¸­ä½äº (j, i) çš„å…ƒç´ ä¸º 1ï¼ˆæœ‰å‘è¾¹ï¼‰ï¼Œæˆ–è€…ä¸¤è€…éƒ½æ˜¯ 1ï¼ˆåŒå‘è¾¹ï¼‰ã€‚
            if A[i, j] == 1:
                #  åœ¨èŠ‚ç‚¹ varnames[j] çš„å­—å…¸ä¸­ï¼Œå°†èŠ‚ç‚¹ varnames[i] æ·»åŠ åˆ°é”® â€˜parâ€™ çš„åˆ—è¡¨ä¸­ï¼Œè¡¨ç¤º varnames[i] æ˜¯ varnames[j] çš„çˆ¶èŠ‚ç‚¹ã€‚
                dag[varnames[j]]['par'].append(varnames[i])
    return dag

# ç”¨äºç”Ÿæˆä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œè¯¥å­—ç¬¦ä¸²æè¿°äº†å›¾çš„å‰å‘çŠ¶æ€ã€‚
# prior: ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦åŒ…å«å…ˆéªŒä¿¡æ¯ï¼Œé»˜è®¤ä¸º Trueã€‚
# prior_type: ä¸€ä¸ªå¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ˜¯å¦åŒ…å«å…ˆéªŒç±»å‹çš„ä¿¡æ¯ï¼Œé»˜è®¤ä¸º Trueã€‚
def generate_name(prior_state, prior=True, prior_type=True):
    st = ''
    for key in prior_state:
        # å¦‚æœå½“å‰é”®å¯¹åº”çš„å…ˆéªŒä¿¡æ¯ä¸º True
        if prior_state[key][0] == True:
            if prior:
                st += key
            if prior_type:
                if prior_state[key][1] == True:
                    st += 'r'
                elif prior_state[key][1] == False:
                    st += 'p'
            st += ','
    #         ç§»é™¤å­—ç¬¦ä¸² st æœ«å°¾çš„åˆ†éš”ç¬¦ â€˜,â€™ã€‚
    st = st.strip(',')
    # å¦‚æœ st ä¸ºç©ºï¼Œåˆ™é»˜è®¤è®¾ç½®ä¸º â€˜nâ€™
    if st == '':
        st = 'n'
    return st

# ç”¨äºè§£æå®éªŒç»“æœæ–‡ä»¶ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸º Pandas DataFrameã€‚
def parse_experiment_results_perform(file_name, column):
    with open(file_name, "r") as f:
        lines = f.readlines()
    res = pd.DataFrame(columns=column)
    for tmp in ["s", "r", "palim"]:
        if tmp in res.columns:
            res[tmp] = res[tmp].astype("int")
    tmp_record = {}
    for line in lines:
        if line[0] == '#':
            continue
        line = line.strip()
        if line.startswith("{"):
            line = line.replace("'", '"')
            line = line.replace("nan", 'null')
            tmp = json.loads(line)
            # add to the pd.dataframe res
            for key in tmp:
                # Add key as a new column name to res
                if key not in res.columns:
                    res[key] = None
                tmp_record[key] = float(
                    tmp[key]) if tmp[key] is not None else np.nan
            res = res.append(tmp_record, ignore_index=True)
            tmp_record = {}
        else:
            if line == '':
                continue
            v_list = line.split(" ")
            for k in v_list:
                key, value = k.split('=')
                try:
                    tmp_record[key] = eval(value)
                except:
                    tmp_record[key] = value
    return res


def parse_prior_results(file_name='exp/path_prior_evaluation.txt'):
    import json

    import pandas as pd
    with open(file_name, "r") as f:
        lines = f.readlines()
    res = pd.DataFrame(columns=["data"])
    props = ["data"]
    tmp_record = {}
    for line in lines:
        line = line.strip()
        if line.startswith("{"):
            line = line.replace("'", '"')
            line = line.replace("nan", 'null')
            tmp = json.loads(line)
            # add to the pd.dataframe res
            for key in tmp:
                # Add key as a new column name to res
                if key not in res.columns:
                    res[key] = None
                tmp_record[key] = float(
                    tmp[key]) if tmp[key] is not None else np.nan
            res = res.append(tmp_record, ignore_index=True)
            tmp_record = {}
        else:
            v_list = line.split(" ")
            for i, k in enumerate(props):
                tmp_record[k] = v_list[i]
    return res

# è¿™ä¸ªå‡½æ•°çš„ä¸»è¦ç›®çš„æ˜¯å°† CSV æ ¼å¼çš„æ•°æ®è½¬æ¢ä¸º Txt æ ¼å¼çš„æ•°æ®ï¼Œä»¥ä¾¿äºåç»­çš„å› æœæ¨æ–­åˆ†æã€‚
def ReconstructData(src_dir='data/csv', dst_dir='data/txt'):
    '''
    reconstruct the data:
    AAA   BBB   CCC
    True  High  Right
    into:
    0 1 2 3 (index)
    2 2 2 2 (arities)
    0 1 0 1 (data)
    '''
    # è¯»å– CSV æ–‡ä»¶ï¼šä½¿ç”¨ pd.read_csv å‡½æ•°è¯»å–æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ CSV æ–‡ä»¶ã€‚
    # è½¬æ¢æ•°æ®ç±»å‹ï¼šå°†æ•°æ®ä¸­çš„åˆ†ç±»æ•°æ®è½¬æ¢ä¸ºæ•´æ•°ç¼–ç ã€‚
    # æå–åˆ—åå’ŒåŸºæ•°ï¼šæå–æ•°æ®ä¸­çš„åˆ—åå’Œæ¯ä¸ªåˆ—çš„å”¯ä¸€å€¼æ•°é‡ã€‚
    # å†™å…¥ Txt æ–‡ä»¶ï¼šå°†è½¬æ¢åçš„æ•°æ®ã€åˆ—åå’ŒåŸºæ•°å†™å…¥æŒ‡å®šç›®å½•çš„ Txt æ–‡ä»¶ä¸­ã€‚
    for path in os.listdir(src_dir):
        data = pd.read_csv(f'{src_dir}/{path}', dtype='category')
        array_data = data.apply(lambda x: x.cat.codes).to_numpy(dtype=int)
        path = path.split('.')[0]
        arities = np.array(data.nunique())
        strtmp = ' '.join([str(i) for i in range(len(data.columns))])
        strtmp += '\n'
        strtmp += ' '.join([str(i) for i in arities])
        np.savetxt(f'{dst_dir}/{path}.txt', array_data,
                   fmt='%d', header=strtmp, comments='')

# è¿™ä¸ªå‡½æ•°ç”¨äºè§£æåŒ…å«çˆ¶èŠ‚ç‚¹å’Œåˆ†æ•°ä¿¡æ¯çš„ Txt æ–‡ä»¶ã€‚å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š
def parse_parents_score(file_path):
    score_dict = {}

    with open(file_path, 'r') as f:
        # read the first line to get the number of nodes (this value is not used in the example)
        node_number = int(f.readline().strip())

        while True:
            line = f.readline().strip()
            if not line:
                break

            # Extract information from the line
            parts = line.split()
            node_index = int(parts[0])
            num_parent_set = int(parts[1])

            # Create an empty list to hold the score and parent information for the current child node
            score_list = []

            # Loop over the number of parent sets and read each set of scores and parents
            for _ in range(num_parent_set):
                line = f.readline().strip()
                parent_parts = line.split()

                # Extract score and parent indices
                score = float(parent_parts[0])
                parent_num = int(parent_parts[1])
                parents = [str(x) for x in parent_parts[2: 2 + parent_num]]

                # Append to the list of scores and parents for this child node
                score_list.append((score, parents))

            # Save to the score_dict
            score_dict[str(node_index)] = score_list

    return score_dict

# è¿™ä¸ªå‡½æ•°ç”¨äºå°†æå–çš„çˆ¶èŠ‚ç‚¹å’Œåˆ†æ•°ä¿¡æ¯å†™å…¥ Txt æ–‡ä»¶ã€‚
def write_parents_score(score_dict, file_path):
    # æ‰“å¼€æ–‡ä»¶ï¼šä½¿ç”¨ with open è¯­å¥æ‰“å¼€æ–‡ä»¶ï¼Œç¡®ä¿æ–‡ä»¶åœ¨ä½¿ç”¨åæ­£ç¡®å…³é—­ã€‚
    # å†™å…¥èŠ‚ç‚¹æ•°é‡ï¼šé¦–å…ˆå†™å…¥æ–‡ä»¶ä¸­çš„èŠ‚ç‚¹æ•°é‡ã€‚
    # å¾ªç¯å†™å…¥èŠ‚ç‚¹ä¿¡æ¯ï¼šå¯¹äºæ¯ä¸ªèŠ‚ç‚¹ï¼Œå†™å…¥èŠ‚ç‚¹çš„ç´¢å¼•ã€çˆ¶èŠ‚ç‚¹é›†çš„æ•°é‡ï¼Œä»¥åŠæ¯ä¸ªçˆ¶èŠ‚ç‚¹é›†çš„åˆ†æ•°å’Œçˆ¶èŠ‚ç‚¹åˆ—è¡¨ã€‚
    with open(file_path, 'w') as f:
        n = len(score_dict)
        f.write(f"{n}\n")
        for var in score_dict:
            f.write(f"{var} {len(score_dict[var])}\n")
            for score, parent_list in score_dict[var]:
                new_score = "{:.8f}".format(score)
                f.write(f"{new_score} {len(parent_list)} {' '.join(parent_list)}\n")
            
# è¿™ä¸ªå‡½æ•°æ£€æŸ¥ç»™å®šçš„ DAG æ˜¯å¦æœ‰ä» source åˆ° dest çš„æœ‰å‘è·¯å¾„ã€‚å®ƒä½¿ç”¨å¹¿åº¦ä¼˜å…ˆæœç´¢ï¼ˆBFSï¼‰æ¥éå† DAGã€‚å¦‚æœæ‰¾åˆ°ä» source åˆ° dest çš„è·¯å¾„ï¼Œåˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
# dag: æ˜¯ä¸€ä¸ª NumPy æ•°ç»„ï¼Œè¡¨ç¤º DAG çš„é‚»æ¥çŸ©é˜µã€‚
# source: æºèŠ‚ç‚¹çš„ç´¢å¼•ã€‚
# dest: ç›®æ ‡èŠ‚ç‚¹çš„ç´¢å¼•ã€‚
def check_path(dag: np.array, source, dest):
    # Check if there is a directed path
    n = dag.shape[0]
    visited = np.zeros(n)
    queue = [source]
    while len(queue) > 0:
        v = queue.pop(0)
        for i in range(n):
            if dag[v][i] == 1 and visited[i] == 0:
                visited[i] = 1
                queue.append(i)
    return visited[dest] == 1

# è¿™ä¸ªå‡½æ•°ç”¨äºåˆ é™¤ DAG ä¸­ç»™å®šç¥–å…ˆå’Œå­èŠ‚ç‚¹å¯¹ä¹‹é—´çš„æ‰€æœ‰è·¯å¾„ã€‚å®ƒä½¿ç”¨ NetworkX åº“æ¥å¤„ç†å›¾ç»“æ„ï¼Œå¹¶åˆ é™¤æ‰€æœ‰å¯èƒ½çš„è·¯å¾„ã€‚
# dag: æ˜¯ä¸€ä¸ª NumPy æ•°ç»„ï¼Œè¡¨ç¤º DAG çš„é‚»æ¥çŸ©é˜µã€‚
# ancs: æ˜¯ä¸€ä¸ªåŒ…å«ç¥–å…ˆå’Œå­èŠ‚ç‚¹å¯¹çš„åˆ—è¡¨ã€‚
def delate_ancs(dag: np.array, ancs):
    G = nx.from_numpy_array(dag, create_using=nx.DiGraph)
    for anc, child in ancs:
        try:
            path = nx.shortest_path(G, source=anc, target=child)
        except:
            path = None
        while path != None:
            for i in range(len(path)-1):
                G.remove_edge(path[i], path[i+1])
            try:
                path = nx.shortest_path(G, source=anc, target=child)
            except:
                path = None
    # è¿”å›ä¸€ä¸ª NumPy æ•°ç»„ï¼Œè¡¨ç¤ºåˆ é™¤è·¯å¾„åçš„ DAGã€‚
    return nx.to_numpy_array(G)

# è¿™ä¸ªå‡½æ•°æ£€æŸ¥ç»™å®šçš„ DAG æ˜¯å¦æ˜¯æ— ç¯çš„ã€‚å®ƒéå†æ‰€æœ‰èŠ‚ç‚¹ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä»æ¯ä¸ªèŠ‚ç‚¹åˆ°è‡ªèº«çš„è·¯å¾„ã€‚å¦‚æœå­˜åœ¨ï¼Œåˆ™è¿”å› Falseï¼Œè¡¨ç¤º DAG ä¸æ˜¯æ— ç¯çš„ï¼›å¦åˆ™è¿”å› Trueã€‚
def check_acyclic(dag: np.array):
    n = dag.shape[0]
    visited = np.zeros(n)
    for i in range(n):
        if visited[i] == 0:
            if check_path(dag, i, i):
                return False
    return True

# è¿™ä¸ªå‡½æ•°å°è¯•å°†ä¸€ä¸ªæœ‰ç¯çš„ DAG è½¬æ¢ä¸ºæ— ç¯çš„ DAGã€‚å®ƒéå†æ‰€æœ‰èŠ‚ç‚¹ï¼Œå¹¶æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä»æ¯ä¸ªèŠ‚ç‚¹åˆ°è‡ªèº«çš„è·¯å¾„ã€‚å¦‚æœå­˜åœ¨ï¼Œå®ƒå°†ç§»é™¤ç¯ä¸­çš„ä¸€ä¸ªè¾¹ã€‚
def cyclic2acyclic(dag: np.array):
    # chekc if the dag is cyclic, if so, make it acyclic
    n = dag.shape[0]
    visited = np.zeros(n)
    for i in range(n):
        if visited[i] == 0:
            if check_path(dag, i, i):
                # find a cycle
                # find the edge in the cycle
                for j in range(n):
                    if dag[i][j] == 1 and check_path(dag, j, i):
                        dag[i][j] = 0
    # print('The algorithm for cycle removement is relatively simple, it can only ensure that the result is acyclic, but cannot ensure that the removed edges are minimal!')
    return dag

# è¿™ä¸ªå‡½æ•°ç”¨äºæ¸…é™¤ DAG ä¸­çš„å¾ªç¯ã€‚å®ƒé¦–å…ˆåˆ›å»ºä¸€ä¸ªä¸çœŸå® DAG å½¢çŠ¶ç›¸åŒçš„é›¶çŸ©é˜µï¼Œç„¶åæ ¹æ®ç»™å®šçš„é¡ºåºçº¦æŸæ·»åŠ è¾¹ã€‚æ¥ç€ï¼Œå®ƒä½¿ç”¨ cyclic2acyclic å‡½æ•°å°è¯•å°† DAG è½¬æ¢ä¸ºæ— ç¯çš„ã€‚
# true_dag: çœŸå® DAG çš„é‚»æ¥çŸ©é˜µã€‚
# order_constraints: è¡¨ç¤ºèŠ‚ç‚¹é¡ºåºçš„çº¦æŸåˆ—è¡¨ã€‚
def clearcycle(true_dag, order_constraints):
    dag = np.zeros(true_dag.shape)
    for edge in order_constraints:
        dag[edge[0], edge[1]] = 1

    dag = cyclic2acyclic(dag)
    # print(check_acyclic(dag))
    edges = np.argwhere(dag == 1)
    edges = [(edge[0], edge[1]) for edge in edges]
    return edges

# è¿™ä¸ªå‡½æ•°ç”¨äºä¿å­˜å› æœæ¨æ–­å®éªŒçš„ç»“æœã€‚å®ƒé¦–å…ˆæ‰“å°å®éªŒçš„è¯¦ç»†ä¿¡æ¯ï¼Œç„¶åå°†è¿™äº›ä¿¡æ¯å†™å…¥ä¸€ä¸ªæ–‡ä»¶ä¸­ã€‚å¦‚æœæ–¹æ³•æ˜¯ DPã€Astarã€ELSA æˆ– PGMINOBSxï¼Œå®ƒè¿˜ä¼šä¿å­˜æ¨æ–­å‡ºçš„ DAG åˆ°æ–‡ä»¶ã€‚
# m: åŒ…å«å®éªŒç»“æœçš„æŒ‡æ ‡å¯¹è±¡ã€‚
# ev_dag: æ¨æ–­å‡ºçš„ DAGã€‚
# **kwargs: åŒ…å«å®éªŒå‚æ•°çš„å­—å…¸ã€‚
def save_result(m, ev_dag, **kwargs):

    print(f"d={kwargs['d']} s={kwargs['s']} r={kwargs['r']} conf={kwargs['conf']} palim={kwargs['palim']} prior={kwargs['prior']} prior_type={kwargs['prior_type']} pruning={kwargs['nopruning']} score={kwargs['score']}  prior_source={kwargs['prior_source']}\n{m.metrics}")
    nowtime = re.sub('\s+', '/', time.asctime(time.localtime()))
    with open(kwargs['output'], 'a') as f:
        f.write(f"d={kwargs['d']} s={kwargs['s']} r={kwargs['r']} conf={kwargs['conf']} palim={kwargs['palim']} prior={kwargs['prior']} prior_type={kwargs['prior_type']} pruning={kwargs['nopruning']} score={kwargs['score']}  prior_source={kwargs['prior_source']} finish_time={nowtime}\n{m.metrics}\n")

    if kwargs['method'] in ['DP', 'Astar', 'ELSA', 'PGMINOBSx']:
        np.savetxt(f"{kwargs['dag_path']}/{kwargs['method']}_{kwargs['d']}_{kwargs['s']}_{kwargs['r']}_{kwargs['palim']}_{kwargs['prior']}_{kwargs['prior_type']}_{kwargs['nopruning']}_{kwargs['score']}_{kwargs['prior_source']}{kwargs['fix']}.txt", ev_dag, fmt="%d")
    elif kwargs['method'] == 'CaMML':
        np.savetxt(f"{kwargs['dag_path']}/{kwargs['method']}_{kwargs['d']}_{kwargs['s']}_{kwargs['r']}_{kwargs['palim']}_{kwargs['prior']}_{kwargs['prior_type']}_{kwargs['prior_source']}{kwargs['fix']}.txt", ev_dag, fmt="%d")
    else:
        np.savetxt(f"{kwargs['dag_path']}/{kwargs['method']}_{kwargs['d']}_{kwargs['s']}_{kwargs['r']}_{kwargs['conf']}_{kwargs['prior']}_{kwargs['prior_type']}_{kwargs['prior_source']}{kwargs['fix']}.txt", ev_dag, fmt="%d")

# è¿™ä¸ªå‡½æ•°ç”¨äºè®¡ç®—å› æœæ¨æ–­å®éªŒçš„æŒ‡æ ‡ï¼Œå¹¶å°†å…¶ä¿å­˜åˆ° CSV æ–‡ä»¶ä¸­ã€‚å®ƒé¦–å…ˆè§£æè¾“å…¥æ–‡ä»¶ï¼Œè®¡ç®—æŒ‡æ ‡ï¼Œç„¶åæ ¹æ® cat_column å’Œ merge_column è¿›è¡Œåˆ†ç»„å’Œèšåˆã€‚
# input: åŒ…å«å®éªŒç»“æœçš„è¾“å…¥æ–‡ä»¶è·¯å¾„ã€‚
# output: åŒ…å«å®éªŒç»“æœç»Ÿè®¡çš„è¾“å‡ºæ–‡ä»¶è·¯å¾„ã€‚
# cat_column: ç”¨äºåˆ†ç»„å’Œèšåˆçš„åˆ—ååˆ—è¡¨ã€‚
# merge_column: ç”¨äºèšåˆçš„åˆ—ååˆ—è¡¨ã€‚
# mean: å¦‚æœä¸º Trueï¼Œåˆ™è®¡ç®—æ¯ä¸ªç»„çš„å¹³å‡å€¼ï¼›å¦åˆ™è®¡ç®—æ¯ä¸ªç»„çš„å€¼ã€‚
def noprior_dag_metric(input="exp/CaMML_noprior.txt", output="exp/CaMML_noprior_statistics.csv", cat_column=["prior", "prior_type", "palim", "d", "s"], merge_column=["r"], mean=True):
    res = parse_experiment_results_perform(
        input, column=cat_column+merge_column)
    # res=res.dropna()
    res['precision'] = res['precision'].fillna(0)
    res['F1'] = res['F1'].fillna(0)

    warnings.filterwarnings("ignore")
    if mean:
        res = res.groupby(cat_column).mean()
    else:
        res.sort_values(cat_column, inplace=True)
        res.reset_index(drop=True, inplace=True)
    res.drop(labels=['fdr', 'tpr', 'fpr', 'nnz', 'r', 'gscore', 'delp_fdr', 'delp_tpr',
             'delp_fpr', 'delp_nnz', 'delp_gscore'], axis=1).to_csv(output, float_format="%.2f")

# åˆ›å»ºæŒ‡å®šè·¯å¾„çš„ç›®å½•ï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œåˆ™ä¸è¿›è¡Œä»»ä½•æ“ä½œã€‚
def mkdir(path):
    """
    make directory, if the directory exists, do nothing
    """
    # ä½¿ç”¨os.path.existså‡½æ•°æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ã€‚
    # å¦‚æœç›®å½•ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨os.makedirså‡½æ•°åˆ›å»ºç›®å½•ã€‚
    # ä½¿ç”¨rprintå‡½æ•°æ‰“å°åˆ›å»ºç›®å½•çš„æç¤ºä¿¡æ¯ã€‚
    if not os.path.exists(path):
        os.makedirs(path)
        rprint(f"ğŸ“‚ Created folder [italic blue]{path}[/italic blue].")

# åˆ›å»ºæŒ‡å®šè·¯å¾„çš„ç›®å½•ï¼Œå¦‚æœç›®å½•å·²å­˜åœ¨ï¼Œåˆ™å…ˆåˆ é™¤ç›®å½•ï¼Œç„¶ååˆ›å»ºæ–°çš„ç›®å½•ã€‚
def mkdir_rm(path):
    """
    make directory, if the directory exists, remove it and create a new one
    """
    # ä½¿ç”¨os.path.existså‡½æ•°æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨ã€‚
    # å¦‚æœç›®å½•å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨shutil.rmtreeå‡½æ•°åˆ é™¤ç›®å½•ã€‚
    # ä½¿ç”¨rprintå‡½æ•°æ‰“å°åˆ é™¤ç›®å½•çš„æç¤ºä¿¡æ¯ã€‚
    # ç„¶åè°ƒç”¨mkdirå‡½æ•°åˆ›å»ºç›®å½•ã€‚
    if os.path.exists(path):
        shutil.rmtree(path)
        rprint(f"ğŸ—‘ï¸  Removed folder [italic blue]{path}[/italic blue].")
    mkdir(path)


# è‡ªåŠ¨æ¸…ç†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶ï¼Œä¿ç•™æœ€æ–°çš„max_numä¸ªæ–‡ä»¶ã€‚
def auto_clean_folder(folder_path, max_num=50):
    # folder_path: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºè¦æ¸…ç†çš„æ–‡ä»¶å¤¹çš„è·¯å¾„ã€‚
    # max_num: æ•´æ•°ï¼Œè¡¨ç¤ºä¿ç•™çš„æ–‡ä»¶æ•°é‡ï¼Œé»˜è®¤ä¸º50ã€‚
    """
    an automatic clean function for folder, keep the latest max_num files
    """
    # ä½¿ç”¨os.listdirå‡½æ•°è·å–æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶åˆ—è¡¨ã€‚
    # æŒ‰ä¿®æ”¹æ—¶é—´å¯¹æ–‡ä»¶åˆ—è¡¨è¿›è¡Œæ’åºï¼Œä»¥ç¡®ä¿æœ€æ–°çš„æ–‡ä»¶æ’åœ¨å‰é¢ã€‚
    # è®¡ç®—éœ€è¦åˆ é™¤çš„æ–‡ä»¶æ•°é‡ã€‚
    # éå†æ–‡ä»¶åˆ—è¡¨ï¼Œåˆ é™¤æ—§æ–‡ä»¶ã€‚
    # ä½¿ç”¨rprintå‡½æ•°æ‰“å°æ¸…ç†æ–‡ä»¶çš„æç¤ºä¿¡æ¯ã€‚
    folder_num = len(os.listdir(folder_path))
    if folder_num > max_num:
        file_list = os.listdir(folder_path)
        file_list.sort(key=lambda fn: os.path.getmtime(
            os.path.join(folder_path, fn)))
        num_to_remove = len(file_list) - max_num
        for i in range(num_to_remove):
            file_path = os.path.join(folder_path, file_list[i])
            if os.path.isfile(file_path):
                os.remove(file_path)
            elif os.path.isdir(file_path):
                os.chmod(file_path, 0o777)
                shutil.rmtree(file_path)
            rprint(f"ğŸ—‘ï¸  Removed file [italic blue]{file_path}[/italic blue].")
        rprint(
            f"â™»ï¸  [bold yellow]Auto clean[/bold yellow] {num_to_remove} files in [italic blue]{folder_path}[/italic blue].")

# å°†å†…å®¹å†™å…¥æŒ‡å®šè·¯å¾„çš„æ–‡æœ¬æ–‡ä»¶ï¼Œå¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œåˆ™è¿½åŠ å†…å®¹ï¼›å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥å†…å®¹ã€‚
# txt_path: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºæ–‡æœ¬æ–‡ä»¶çš„è·¯å¾„ã€‚
# content: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºè¦å†™å…¥æ–‡ä»¶çš„å†…å®¹ã€‚
# mode: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºå†™å…¥æ¨¡å¼ï¼Œé»˜è®¤ä¸º"w"ï¼ˆè¦†ç›–å†™å…¥ï¼‰ï¼Œå¯é€‰ä¸º"a"ï¼ˆè¿½åŠ å†™å…¥ï¼‰ã€‚
def write_txt(txt_path, content,mode="w"):
    """
    write content to txt file
    """
    with open(txt_path, mode, encoding='utf-8') as f:
        f.write(content)
    if mode=="w":
        rprint(
            f"ğŸ“ Write [bold yellow]txt[/bold yellow] file to [italic blue]{txt_path}[/italic blue].")
    else:
        rprint(
            f"ğŸ“ Append [bold yellow]txt[/bold yellow] file to [italic blue]{txt_path}[/italic blue].")


# è¿™ä¸ªå‡½æ•°ç”¨äºè‡ªåŠ¨æ£€æµ‹æ–‡ä»¶çš„å­—ç¬¦ç¼–ç ã€‚å®ƒä½¿ç”¨ chardet åº“æ¥æ£€æµ‹æ–‡ä»¶å†…å®¹çš„ç¼–ç ï¼Œå¹¶å°†æ£€æµ‹åˆ°çš„ç¼–ç å†™å…¥æ§åˆ¶å°ã€‚
# å‚æ•°ï¼š
# file_path: æ–‡ä»¶çš„è·¯å¾„ã€‚
# è¿”å›å€¼ï¼š
# è¿”å›æ–‡ä»¶çš„å­—ç¬¦ç¼–ç ã€‚
def auto_detect_encoding(file_path):
    """
    detect encoding of file automatically
    """
    with open(file_path, 'rb') as f:
        encoding = chardet.detect(f.read())['encoding']
    rprint(
        f"ğŸ” Detected encoding: [bold yellow]{encoding}[/bold yellow] of [italic blue]{file_path}[/italic blue].")
    return encoding


# è¿™ä¸ªå‡½æ•°ç”¨äºè¯»å–æ–‡æœ¬æ–‡ä»¶ã€‚å¦‚æœæŒ‡å®š encoding ä¸º 'auto'ï¼Œå®ƒä¼šè‡ªåŠ¨æ£€æµ‹æ–‡ä»¶çš„ç¼–ç ã€‚
# txt_path: æ–‡æœ¬æ–‡ä»¶çš„è·¯å¾„ã€‚
# encoding: æ–‡ä»¶çš„å­—ç¬¦ç¼–ç ã€‚
def read_txt(txt_path, encoding='utf-8'):
    """
    read txt file
    use utf-8 as default encoding, if you want to auto detect encoding, set encoding='auto'
    """
    if encoding == 'auto':
        encoding = auto_detect_encoding(txt_path)
    with open(txt_path, "r", encoding=encoding) as f:
        content = f.read()
    rprint(
        f"ğŸ“– Read [bold yellow]txt[/bold yellow] file from [italic blue]{txt_path}[/italic blue].")
    # è¿”å›æ–‡æœ¬æ–‡ä»¶çš„å†…å®¹ã€‚
    return content

# è¿™ä¸ªå‡½æ•°ç”¨äºå°†å†…å®¹å†™å…¥ JSON æ–‡ä»¶ã€‚å®ƒå¯ä»¥æ¥å—å­—å…¸ã€åˆ—è¡¨æˆ–å…¶ä»–å¯åºåˆ—åŒ–ä¸º JSON çš„å¯¹è±¡ã€‚
# content: éœ€è¦å†™å…¥çš„ JSON åºåˆ—åŒ–å¯¹è±¡ã€‚
# json_path: JSON æ–‡ä»¶çš„è·¯å¾„ã€‚
# encoding: JSON æ–‡ä»¶çš„ç¼–ç ã€‚
# indent: JSON æ–‡ä»¶çš„ç¼©è¿›ã€‚
def write_json(content, json_path, encoding='utf-8', indent=4):
    """
    Write content to json file.

    Args:
        content: dict, list, or other json serializable object.
        json_path: str, path to json file.
        encoding: str, encoding of json file.
        indent: int, indent of json file.
    """
    try:
        # ç¡®ä¿åŒ…å«æ–‡ä»¶çš„ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(json_path), exist_ok=True)
        with open(json_path, "w", encoding=encoding) as f:
            json.dump(content, f, ensure_ascii=False, indent=indent)
        rprint(
            f"ğŸ“ Write [bold yellow]json[/bold yellow] file to [italic blue]{json_path}[/italic blue].")
    except IOError as e:
        # å¤„ç†IOé”™è¯¯ï¼Œä¾‹å¦‚æƒé™é—®é¢˜æˆ–å…¶ä»–I/Oç›¸å…³é”™è¯¯
        rprint(f"An IOError occurred: {e}")
    except Exception as e:
        # å¤„ç†å…¶ä»–å¯èƒ½çš„å¼‚å¸¸
        rprint(f"An unexpected error occurred: {e}")

# ä»æŒ‡å®šçš„JSONæ–‡ä»¶è·¯å¾„è¯»å–æ–‡ä»¶å†…å®¹ã€‚
# json_path: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºJSONæ–‡ä»¶çš„è·¯å¾„ã€‚
# encoding: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºæ–‡ä»¶ç¼–ç ï¼Œé»˜è®¤ä¸ºâ€™utf-8â€™ï¼Œå¦‚æœæŒ‡å®šä¸ºâ€™autoâ€™ï¼Œåˆ™è‡ªåŠ¨æ£€æµ‹ç¼–ç ã€‚
# quiet: å¸ƒå°”å€¼ï¼Œå¦‚æœä¸ºFalseï¼Œåˆ™æ‰“å°æˆåŠŸè¯»å–çš„æç¤ºä¿¡æ¯ï¼Œé»˜è®¤ä¸ºFalseã€‚
def read_json(json_path, encoding='utf-8',quiet=False):
    """
    read json file
    """
    # å¦‚æœæŒ‡å®šencodingä¸ºâ€™autoâ€™ï¼Œåˆ™ä½¿ç”¨auto_detect_encodingå‡½æ•°è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç ã€‚
    # ä½¿ç”¨openå‡½æ•°ä»¥è¯»å–æ¨¡å¼æ‰“å¼€æ–‡ä»¶ï¼Œå¹¶æŒ‡å®šæ­£ç¡®çš„ç¼–ç ã€‚
    # ä½¿ç”¨json.loadå‡½æ•°è¯»å–æ–‡ä»¶å†…å®¹ã€‚
    # å¦‚æœquietä¸ºFalseï¼Œåˆ™ä½¿ç”¨rprintå‡½æ•°æ‰“å°æˆåŠŸè¯»å–çš„æç¤ºä¿¡æ¯ã€‚
    # è¿”å›è¯»å–çš„JSONå†…å®¹ã€‚
    if encoding == 'auto':
        encoding = auto_detect_encoding(json_path)
    with open(json_path, "r", encoding=encoding) as f:
        content = json.load(f)
    if not quiet:
        rprint(
            f"ğŸ“– Read [bold yellow]json[/bold yellow] file from [italic blue]{json_path}[/italic blue].")
    #     è¿”å›å€¼ï¼šè¯»å–çš„JSONå†…å®¹ï¼Œä»¥Pythonå­—å…¸æˆ–åˆ—è¡¨çš„å½¢å¼è¿”å›ã€‚
    return content

# è¯»å–JSONæ–‡ä»¶ï¼Œæ›´æ–°æ–‡ä»¶å†…å®¹ï¼Œå¹¶å†™å›æ–‡ä»¶ã€‚
# add_content: å­—å…¸æˆ–åˆ—è¡¨ï¼Œè¡¨ç¤ºè¦æ·»åŠ åˆ°JSONæ–‡ä»¶çš„å†…å®¹ã€‚
# json_path: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºJSONæ–‡ä»¶çš„è·¯å¾„ã€‚
# encoding: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºæ–‡ä»¶ç¼–ç ï¼Œé»˜è®¤ä¸ºâ€™utf-8â€™ï¼Œå¦‚æœæŒ‡å®šä¸ºâ€™autoâ€™ï¼Œåˆ™è‡ªåŠ¨æ£€æµ‹ç¼–ç ã€‚
def update_json(add_content, json_path, encoding='utf-8'):
    """
    update json file
    """
    # å¦‚æœæŒ‡å®šencodingä¸ºâ€™autoâ€™ï¼Œåˆ™ä½¿ç”¨auto_detect_encodingå‡½æ•°è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç ã€‚
    # ä½¿ç”¨openå‡½æ•°ä»¥è¯»å–æ¨¡å¼æ‰“å¼€æ–‡ä»¶ï¼Œå¹¶æŒ‡å®šæ­£ç¡®çš„ç¼–ç ã€‚
    # ä½¿ç”¨json.loadå‡½æ•°è¯»å–æ–‡ä»¶å†…å®¹ã€‚
    # å°†add_contentæ·»åŠ åˆ°contentå­—å…¸æˆ–åˆ—è¡¨ä¸­ã€‚
    # ä½¿ç”¨openå‡½æ•°ä»¥å†™å…¥æ¨¡å¼æ‰“å¼€æ–‡ä»¶ï¼Œå¹¶æŒ‡å®šæ­£ç¡®çš„ç¼–ç ã€‚
    # ä½¿ç”¨json.dumpå‡½æ•°å°†æ›´æ–°åçš„å†…å®¹å†™å›æ–‡ä»¶ï¼Œå¹¶æŒ‡å®šç¡®ä¿éASCIIå­—ç¬¦çš„è¾“å‡ºã€ç¼©è¿›ç­‰å‚æ•°ã€‚
    # ä½¿ç”¨rprintå‡½æ•°æ‰“å°æˆåŠŸæ›´æ–°çš„æç¤ºä¿¡æ¯ã€‚
    if encoding == 'auto':
        encoding = auto_detect_encoding(json_path)
    with open(json_path, "r", encoding=encoding) as f:
        content = json.load(f)
    content.update(add_content)
    with open(json_path, "w", encoding=encoding) as f:
        json.dump(content, f, ensure_ascii=False, indent=4)
    rprint(
        f"ğŸ”„ Update [bold yellow]json[/bold yellow] file to [italic blue]{json_path}[/italic blue].")

# è¯»å–JSONæ–‡ä»¶ï¼Œè¿½åŠ å†…å®¹åˆ°æ–‡ä»¶ï¼Œå¹¶å†™å›æ–‡ä»¶
def append_json(add_content, json_path, encoding='utf-8'):
    """
    append json file
    """
    if encoding == 'auto':
        encoding = auto_detect_encoding(json_path)
    with open(json_path, "r", encoding=encoding) as f:
        content = json.load(f)
    content.append(add_content)
    with open(json_path, "w", encoding=encoding) as f:
        json.dump(content, f, ensure_ascii=False, indent=4)
    rprint(
        f"ğŸ”„ Update [bold yellow]json[/bold yellow] file to [italic blue]{json_path}[/italic blue].")

# è¿™ä¸ªè£…é¥°å™¨ç”¨äºè¿‡æ»¤è­¦å‘Šã€‚
# å®ƒé¦–å…ˆè°ƒç”¨ warnings.filterwarnings("ignore") æ¥ç¦ç”¨è­¦å‘Šï¼Œ
# ç„¶åæ‰§è¡ŒåŸå§‹å‡½æ•° funcï¼Œ
# æœ€åè°ƒç”¨ warnings.filterwarnings("default") æ¥æ¢å¤é»˜è®¤è­¦å‘Šè®¾ç½®ã€‚

# func: éœ€è¦è£…é¥°çš„å‡½æ•°ã€‚
def warning_filter(func):
    """
    a decorator to filter warnings
    """
    def inner(*args, **kwargs):
        warnings.filterwarnings("ignore")
        result = func(*args, **kwargs)
        warnings.filterwarnings("default")
        return result
    # è¿”å›å€¼ï¼š
    # è¿”å›åŸå§‹å‡½æ•° func çš„æ‰§è¡Œç»“æœã€‚
    return inner

# è¿™ä¸ªè£…é¥°å™¨ç”¨äºè®¡ç®—å‡½æ•°çš„æ‰§è¡Œæ—¶é—´ã€‚å®ƒé¦–å…ˆè®°å½•å‡½æ•°å¼€å§‹æ‰§è¡Œçš„æ—¶é—´ï¼Œç„¶åæ‰§è¡ŒåŸå§‹å‡½æ•° funcï¼Œæœ€åè®°å½•å‡½æ•°ç»“æŸæ‰§è¡Œçš„æ—¶é—´ï¼Œå¹¶è®¡ç®—æ—¶é—´å·®ã€‚
def timer(func):
    """
    a decorator to calculate the time cost of a function
    """
    def inner(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        rprint(
            f"â±ï¸ Function [italic blue]{func.__name__}[/italic blue] cost [bold yellow]{end-start:.4f}[/bold yellow] seconds.")
        return result
    return inner

# è¿™ä¸ªå‡½æ•°ç”¨äºå¯¹åˆ—è¡¨è¿›è¡Œæ’åºã€‚
# å®ƒæ¥å—ä¸€ä¸ªåŒ…å«å…ƒç»„çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç»„åŒ…å«ä¸¤ä¸ªå…ƒç´ ï¼šç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªé”®å€¼å¯¹ï¼Œç¬¬äºŒä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå€¼ã€‚å‡½æ•°å°†åˆ—è¡¨ä¸­çš„å…ƒç»„æŒ‰ç…§é”®è¿›è¡Œæ’åºï¼Œå¹¶å°†æ’åºåçš„ç»“æœå­˜å‚¨åœ¨å­—å…¸ä¸­ã€‚
def sort(list):
    result = {}
    for tuple in list:
        if tuple[0][1] not in result.keys():
            result[tuple[0][1]] = {}
            result[tuple[0][1]][tuple[0][0]] = tuple[1]
        else:
            result[tuple[0][1]][tuple[0][0]] = tuple[1]
    # è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­é”®æ˜¯æ’åºåçš„é”®å€¼å¯¹ï¼Œå€¼æ˜¯ç›¸åº”çš„å€¼ã€‚
    return result


# è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º soft_constraint çš„ç±»ï¼Œç”¨äºè¡¨ç¤ºè½¯çº¦æŸã€‚
# è½¯çº¦æŸæ˜¯æŒ‡åœ¨å› æœæ¨æ–­ä¸­ï¼ŒæŸäº›è¾¹å¯èƒ½æ˜¯å¼ºåˆ¶çš„ï¼ˆobligatoryï¼‰ï¼Œè€Œå…¶ä»–è¾¹åˆ™å¯èƒ½è¢«ç¦æ­¢ï¼ˆforbiddenï¼‰ã€‚
# è¿™äº›çº¦æŸé€šè¿‡ lambda å‡½æ•°æ¥è¡¨ç¤ºï¼Œå…¶ä¸­ lambda[0] è¡¨ç¤ºå¼ºåˆ¶è¾¹çš„æƒé‡ï¼Œè€Œ lambda[1] è¡¨ç¤ºç¦æ­¢è¾¹çš„æƒé‡ã€‚
class soft_constraint:
    # obligatory: å¼ºåˆ¶è¾¹çš„åˆ—è¡¨ï¼Œæ¯ä¸ªè¾¹ç”±ä¸¤ä¸ªå…ƒç´ ç»„æˆï¼Œåˆ†åˆ«è¡¨ç¤ºçˆ¶èŠ‚ç‚¹å’Œå­èŠ‚ç‚¹ã€‚
    # forbidden: ç¦æ­¢è¾¹çš„åˆ—è¡¨ï¼Œæ¯ä¸ªè¾¹ç”±ä¸¤ä¸ªå…ƒç´ ç»„æˆï¼Œåˆ†åˆ«è¡¨ç¤ºçˆ¶èŠ‚ç‚¹å’Œå­èŠ‚ç‚¹ã€‚
    # lamdba: æƒé‡åˆ—è¡¨ï¼ŒåŒ…å«å¼ºåˆ¶è¾¹æƒé‡å’Œç¦æ­¢è¾¹æƒé‡ã€‚
    def __init__(self, obligatory, forbidden, lamdba):
        # 3 parameters: obligatory edges, forbidden edges, lambda
        # å±æ€§:
        # obligatory: å­˜å‚¨å¼ºåˆ¶è¾¹çš„å­—å…¸ï¼Œå…¶ä¸­é”®æ˜¯å­èŠ‚ç‚¹ï¼Œå€¼æ˜¯çˆ¶èŠ‚ç‚¹çš„æƒé‡ã€‚
        # forbidden: å­˜å‚¨ç¦æ­¢è¾¹çš„å­—å…¸ï¼Œå…¶ä¸­é”®æ˜¯å­èŠ‚ç‚¹ï¼Œå€¼æ˜¯çˆ¶èŠ‚ç‚¹çš„æƒé‡ã€‚
        self.obligatory = sort([(x, y) for x, y in zip(obligatory, lamdba[0])])
        self.forbidden = sort([(x, y) for x, y in zip(forbidden, lamdba[1])])

    # è®¡ç®—ç»™å®šå˜é‡ var åœ¨å…¶çˆ¶èŠ‚ç‚¹é›†åˆ parent ä¸‹çš„å…ˆéªŒå¾—åˆ†ã€‚è¿™ä¸ªå¾—åˆ†åæ˜ äº†è½¯çº¦æŸå¯¹æ¨æ–­çš„å½±å“ï¼Œå…¶ä¸­è½¯çº¦æŸåŒ…æ‹¬å¼ºåˆ¶è¾¹ï¼ˆobligatory edgesï¼‰å’Œç¦æ­¢è¾¹ï¼ˆforbidden edgesï¼‰ã€‚
    # var: å½“å‰å˜é‡ã€‚
    # parent: å½“å‰å˜é‡çš„çˆ¶èŠ‚ç‚¹é›†åˆã€‚
    def calculate(self, var, parent):
        prior_score = 0
        if var in self.obligatory.keys():
            for p in self.obligatory[var].keys():
                if p in parent:
                    prior_score += math.log(self.obligatory[var][p])
                else:
                    prior_score += math.log(1-self.obligatory[var][p])
        if var in self.forbidden.keys():
            for p in self.forbidden[var].keys():
                if p in parent:
                    prior_score += math.log(1-self.forbidden[var][p])
                else:
                    prior_score += math.log(self.forbidden[var][p])
        # è¿”å› prior_scoreï¼Œå³æ ¹æ®å½“å‰å˜é‡å’Œçˆ¶èŠ‚ç‚¹è®¡ç®—å‡ºçš„å…ˆéªŒå¾—åˆ†ã€‚
        return prior_score

class ColorP:
    def __init__(self) -> None:
        pass

    # åŠŸèƒ½ï¼šå°†ç»™å®šçš„è¾¹æ·»åŠ é¢œè‰²ï¼Œä½¿å…¶å‘ˆç°ç´«è‰²ã€‚
    # å‚æ•°ï¼š
    # edge: åˆ—è¡¨ï¼ŒåŒ…å«ä¸¤ä¸ªå…ƒç´ ï¼Œåˆ†åˆ«è¡¨ç¤ºè¾¹çš„èµ·ç‚¹å’Œç»ˆç‚¹ã€‚
    @staticmethod
    def edge(edge):
        start, end = edge
        # # è¿”å›å€¼ï¼šå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºå¸¦æœ‰é¢œè‰²çš„è¾¹ã€‚
        return f"[purple]{start}[/purple]->[purple]{end}[/purple]"
    # æ ¹æ®ç­”æ¡ˆå’ŒçœŸå®ç­”æ¡ˆçš„åŒ¹é…æƒ…å†µï¼Œæ·»åŠ ä¸åŒçš„é¢œè‰²å’Œæ ·å¼ã€‚
    # answer: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºç”¨æˆ·çš„ç­”æ¡ˆã€‚
    # true_ans: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºçœŸå®çš„ç­”æ¡ˆã€‚
    # å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºå¸¦æœ‰é¢œè‰²å’Œæ ·å¼çš„ç­”æ¡ˆã€‚
    @staticmethod
    def answer(answer, true_ans):
        if answer == "D":  # answer is uncertain
            return f"(Ans: [yellow]{answer}[/yellow] / [green]{true_ans}[/green])"
        elif answer == true_ans:  # answer is correct
            if answer in ["B", "C"]:  # the correct answer makes effect
                return f"(Ans: [bold green]{answer}[/bold green] / [green]{true_ans}[/green])"
            else:  # the correct answer does not make effect
                return f"(Ans: [green]{answer}[/green] / [green]{true_ans}[/green])"
        elif answer == "A":  # answer is wrong, but does not make effect
            return f"(Ans: [yellow]{answer}[/yellow] / [green]{true_ans}[/green])"
        else:  # answer is wrong, and makes effect
            return f"(Ans: [bold red]{answer}[/bold red] / [green]{true_ans}[/green])"
    # å°†ç»™å®šçš„çœŸå®ç­”æ¡ˆæ·»åŠ é¢œè‰²ï¼Œä½¿å…¶å‘ˆç°é»„è‰²ã€‚
    # GT: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºçœŸå®ç­”æ¡ˆ
    @staticmethod
    def GT(GT):
        # å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºå¸¦æœ‰é¢œè‰²çš„çœŸå®ç­”æ¡ˆã€‚
        return f"(TrueAns: [yellow]{GT}[/yellow])"

    # åŠŸèƒ½ï¼šå°†ç»™å®šçš„æ¨¡å‹æ·»åŠ é¢œè‰²å’Œæ ·å¼ï¼Œä½¿å…¶å‘ˆç°é»„è‰²å¹¶åŠ ç²—ã€‚
    # å‚æ•°ï¼š
    # model: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºæ¨¡å‹åç§°æˆ–æè¿°ã€‚
    # è¿”å›å€¼ï¼šå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºå¸¦æœ‰é¢œè‰²å’Œæ ·å¼çš„æ¨¡å‹ã€‚
    @staticmethod
    def model(model):
        return f"[bold yellow]{model}[/bold yellow]"

    # åŠŸèƒ½ï¼šå°†ç»™å®šçš„è·¯å¾„æ·»åŠ é¢œè‰²å’Œæ ·å¼ï¼Œä½¿å…¶å‘ˆç°è“è‰²å¹¶å€¾æ–œã€‚
    # å‚æ•°ï¼š
    # path: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºè·¯å¾„ã€‚
    # è¿”å›å€¼ï¼šå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºå¸¦æœ‰é¢œè‰²å’Œæ ·å¼çš„è·¯å¾„ã€‚
    @staticmethod
    def path(path):
        return f"[italic blue]{path}[/italic blue]"

    # åŠŸèƒ½ï¼šå°†ç»™å®šçš„è­¦å‘Šå†…å®¹æ·»åŠ é¢œè‰²ï¼Œä½¿å…¶å‘ˆç°çº¢è‰²ã€‚
    # å‚æ•°ï¼š
    # content: å­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºè­¦å‘Šä¿¡æ¯ã€‚
    # è¿”å›å€¼ï¼šå­—ç¬¦ä¸²ï¼Œè¡¨ç¤ºå¸¦æœ‰é¢œè‰²çš„è­¦å‘Šä¿¡æ¯ã€‚
    @staticmethod
    def warning(content):
        return f"[red]{content}[/red]"

if __name__ == "__main__":
    score_dict = parse_parents_score("data/score/bdeu/asia_1000_1.txt")
    write_parents_score(score_dict,"test_score.tmp")